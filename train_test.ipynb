{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fire\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from plain_cnn import PlainCNN\n",
    "from mlp import MLP\n",
    "import chainer\n",
    "from chainer import computational_graph\n",
    "from chainer import optimizers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sobamchan.sobamchan_iterator import Iterator\n",
    "from sobamchan.sobamchan_log import Log\n",
    "from sobamchan.sobamchan_slack import Slack\n",
    "from sobamchan import sobamchan_chainer\n",
    "slack = Slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResBlock(sobamchan_chainer.Model):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResBlock, self).__init__(\n",
    "            conv1=L.Convolution2D(in_channels, out_channels, ksize=(3,3), stride=1, pad=1),\n",
    "            conv2=L.Convolution2D(out_channels, out_channels, ksize=(3,3), stride=1, pad=1),\n",
    "            bn1=L.BatchNormalization(out_channels),\n",
    "            bn2=L.BatchNormalization(out_channels),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        h = self.fwd(x, train)\n",
    "        return h\n",
    "\n",
    "    def fwd(self, x, train=True):\n",
    "        h = F.relu(self.bn1((self.conv1(x))))\n",
    "        h = F.relu(self.bn2((self.conv2(h))))\n",
    "        _, x_channels, _, _ = x.shape\n",
    "        h_batch_size, h_channels, h_h, h_w = h.shape\n",
    "        if x_channels != h_channels:\n",
    "            pad = chainer.Variable(np.zeros((h_batch_size, h_channels - x_channels, h_h, h_w)).astype(np.float32))\n",
    "            if np.ndarray is not type(h.data):\n",
    "                pad.to_gpu()\n",
    "            return h + F.concat((x, pad))\n",
    "        return h + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = chainer.datasets.cifar.get_cifar10()\n",
    "train_x = np.array([x[0] for x in train])\n",
    "train_t = np.array([x[1] for x in train])\n",
    "test_x = np.array([x[0] for x in test])\n",
    "test_t = np.array([x[1] for x in test])\n",
    "train_n = len(train_x)\n",
    "test_n = len(test_x)\n",
    "train_x = train_x.reshape(train_n, 3, 32, 32)\n",
    "test_x = test_x.reshape(test_n, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.subtract(train_x, np.mean(train_x, axis=0))\n",
    "test_x = np.subtract(test_x, np.mean(test_x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 3, 32, 32)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "x_batch = train_x[:256]\n",
    "print(x_batch.shape)\n",
    "t_batch = train_t[:256]\n",
    "print(t_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resblock = ResBlock(3, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = resblock(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 64, 32, 32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet(sobamchan_chainer.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        layer_i = 1\n",
    "        n = 2\n",
    "        modules = []\n",
    "        input_channel = 3\n",
    "        # 16 layer, 32 * 32 output map size\n",
    "        for i in range(layer_i, layer_i+n*2+1):\n",
    "            modules += [('resblock_{}'.format(layer_i), ResBlock(input_channel, 16, stride=1))]\n",
    "            input_channel = 16\n",
    "            layer_i += 1\n",
    "        # 32 layer\n",
    "        for i in range(layer_i, layer_i+n*2):\n",
    "            if i+layer_i != layer_i+n*2:\n",
    "                modules += [('resblock_{}'.format(layer_i), ResBlock(input_channel, 32, stride=1))]\n",
    "            else:\n",
    "                modules += [('resblock_{}'.format(layer_i), ResBlock(input_channel, 32, stride=2))]\n",
    "            input_channel = 16\n",
    "            layer_i += 1\n",
    "        # 64 layer\n",
    "        for i in range(layer_i, layer_i+n*2):\n",
    "            if i+layer_i != layer_i+n*2:\n",
    "                modules += [('resblock_{}'.format(layer_i), ResBlock(input_channel, 64, stride=1))]\n",
    "            else:\n",
    "                modules += [('resblock_{}'.format(layer_i), ResBlock(input_channel, 64, stride=2))]\n",
    "            input_channel = 8\n",
    "            layer_i += 1\n",
    "\n",
    "        modules += [('fc', L.Linear(None, 10))]\n",
    "        \n",
    "        # register\n",
    "        [ self.add_link(*link) for link in modules ]\n",
    "        self.modules = modules\n",
    "        self.layer_n = layer_i\n",
    "\n",
    "    def __call__(self, x, t, train=True):\n",
    "        y = self.fwd(x, train)\n",
    "        return F.softmax_cross_entropy(y, t), F.accuracy(y, t)\n",
    "\n",
    "    def fwd(self, x, train=True):\n",
    "        # convs and bns\n",
    "        for i in range(1, self.layer_n-1):\n",
    "            if i == 1:\n",
    "                x = F.max_pooling_2d(x, (2,2), stride=1)\n",
    "\n",
    "        x = F.average_pooling_2d(x, (2,2), stride=1)\n",
    "        # fc\n",
    "        x = self['fc'](x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resnet = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, acc = resnet(x_batch, t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.078125, dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
